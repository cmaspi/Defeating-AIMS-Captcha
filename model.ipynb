{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 00:29:51.459334: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-18 00:29:51.459358: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "dataset = np.load('character.npy', allow_pickle = True)\n",
    "\n",
    "# separating images and labels\n",
    "labels = dataset[:,1]\n",
    "images = dataset[:,0]\n",
    "\n",
    "# The different classes of labels, example: 2,3,A,B,C,x,y etc\n",
    "classes = np.unique(labels)\n",
    "\n",
    "# Making a dictionary to get a numeric equivalent of all classes\n",
    "classes = {classes[i]:i for i in range(classes.__len__())}\n",
    "labels = np.array([classes[i] for i in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x : np.ndarray, y: np.ndarray):\n",
    "    \"\"\"\n",
    "    Splits the data into 80-20 train-test split.\n",
    "    \"\"\"\n",
    "    def __shuffle__(x,y):\n",
    "        \"\"\"\n",
    "        Shuffles the data\n",
    "        \"\"\"\n",
    "        n = y.shape[0]\n",
    "        permutation = np.random.permutation(n)\n",
    "        return x[permutation], y[permutation]\n",
    "    \n",
    "    x,y = __shuffle__(x,y)\n",
    "    n = y.shape[0]\n",
    "    train_x = x[:int(n*0.8)]\n",
    "    test_x = x[int(n*0.8):]\n",
    "    train_y = y[:int(n*0.8)]\n",
    "    test_y = y[int(n*0.8):]\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "train_x, train_y, test_x, test_y = train_test_split(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-18 00:29:53.316767: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-18 00:29:53.316800: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-18 00:29:53.316824: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dino): /proc/driver/nvidia/version does not exist\n",
      "2022-05-18 00:29:53.317115: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-18 00:29:59.734670: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 876787200 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Converting our numpy data to tensors\n",
    "train_x = tf.convert_to_tensor([tf.convert_to_tensor(i, np.uint8) for i in train_x])\n",
    "train_y = tf.convert_to_tensor([tf.convert_to_tensor(i, np.uint8) for i in train_y])\n",
    "test_x = tf.convert_to_tensor([tf.convert_to_tensor(i, np.uint8) for i in test_x])\n",
    "test_y = tf.convert_to_tensor([tf.convert_to_tensor(i, np.uint8) for i in test_y])\n",
    "\n",
    "# The image has all dtype of int,\n",
    "# but we need float for our calculations\n",
    "# So, we will cast the tensors to float datatype\n",
    "train_x = tf.cast(train_x, tf.float64)\n",
    "test_x = tf.cast(test_x, tf.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our model\n",
    "# It consists of a Convolutional layer with 5 kernels\n",
    "# followed by max pooling layer\n",
    "# followed by another convolutional layer with with 5 kernels\n",
    "# followed by yes you guessed it, max pooling layer\n",
    "# Then a flattening layer\n",
    "# followed by an mlp with 81 neurons in hidden layer\n",
    "# and finally 51 in the output layer\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(5, (2,2), activation='relu', input_shape = (30,30,1)))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(5, (2,2), activation = 'relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(81, activation='relu'))\n",
    "model.add(layers.Dense(51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 29, 29, 5)         25        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 5)         105       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 5)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 81)                14661     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 51)                4182      \n",
      "=================================================================\n",
      "Total params: 18,973\n",
      "Trainable params: 18,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3806/3806 [==============================] - 31s 8ms/step - loss: 0.6934 - sparse_categorical_accuracy: 0.8364 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9584\n",
      "Epoch 2/15\n",
      "3806/3806 [==============================] - 29s 8ms/step - loss: 0.0172 - sparse_categorical_accuracy: 0.9713 - val_loss: 0.0056 - val_sparse_categorical_accuracy: 0.9786\n",
      "Epoch 3/15\n",
      "3806/3806 [==============================] - 28s 7ms/step - loss: 0.0110 - sparse_categorical_accuracy: 0.9824 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9851\n",
      "Epoch 4/15\n",
      "3806/3806 [==============================] - 29s 7ms/step - loss: 0.0042 - sparse_categorical_accuracy: 0.9871 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 0.9887\n",
      "Epoch 5/15\n",
      "3806/3806 [==============================] - 29s 8ms/step - loss: 0.0057 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.0149 - val_sparse_categorical_accuracy: 0.9907\n",
      "Epoch 6/15\n",
      "3806/3806 [==============================] - 29s 8ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.0038 - val_sparse_categorical_accuracy: 0.9921\n",
      "Epoch 7/15\n",
      "3806/3806 [==============================] - 28s 7ms/step - loss: 0.0027 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.0035 - val_sparse_categorical_accuracy: 0.9932\n",
      "Epoch 8/15\n",
      "3806/3806 [==============================] - 29s 8ms/step - loss: 9.4693e-07 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 0.9940\n",
      "Epoch 9/15\n",
      "3806/3806 [==============================] - 30s 8ms/step - loss: 8.3666e-08 - sparse_categorical_accuracy: 0.9944 - val_loss: 0.0030 - val_sparse_categorical_accuracy: 0.9947\n",
      "Epoch 10/15\n",
      "3806/3806 [==============================] - 29s 8ms/step - loss: 2.6078e-08 - sparse_categorical_accuracy: 0.9950 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 0.9952\n",
      "Epoch 11/15\n",
      "3806/3806 [==============================] - 28s 7ms/step - loss: 6.2475e-09 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0028 - val_sparse_categorical_accuracy: 0.9956\n",
      "Epoch 12/15\n",
      "3806/3806 [==============================] - 28s 7ms/step - loss: 1.2501e-09 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 0.9960\n",
      "Epoch 13/15\n",
      "3806/3806 [==============================] - 29s 8ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9961 - val_loss: 0.0031 - val_sparse_categorical_accuracy: 0.9963\n",
      "Epoch 14/15\n",
      "3806/3806 [==============================] - 28s 7ms/step - loss: 0.0043 - sparse_categorical_accuracy: 0.9963 - val_loss: 0.0072 - val_sparse_categorical_accuracy: 0.9965\n",
      "Epoch 15/15\n",
      "3806/3806 [==============================] - 28s 7ms/step - loss: 0.0024 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c5cedc5b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "            )\n",
    "model.fit(train_x, train_y, epochs = 15, validation_data = (test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"myModel.h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
