{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 23:46:29.874446: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-17 23:46:29.874506: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('character.npy', allow_pickle = True)\n",
    "labels = dataset[:,1]\n",
    "images = dataset[:,0]\n",
    "\n",
    "classes = np.unique(labels)\n",
    "classes = {classes[i]:i for i in range(classes.__len__())}\n",
    "labels = np.array([classes[i] for i in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36, 29,  5, ..., 11,  2,  2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(x : np.ndarray, y: np.ndarray):\n",
    "    def __shuffle__(x,y):\n",
    "        \"\"\"\n",
    "        Shuffles the data\n",
    "        \"\"\"\n",
    "        n = y.shape[0]\n",
    "        permutation = np.random.permutation(n)\n",
    "        return x[permutation], y[permutation]\n",
    "    \n",
    "    x,y = __shuffle__(x,y)\n",
    "    n = y.shape[0]\n",
    "    train_x = x[:int(n*0.8)]\n",
    "    test_x = x[int(n*0.8):]\n",
    "    train_y = y[:int(n*0.8)]\n",
    "    test_y = y[int(n*0.8):]\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "train_x, train_y, test_x, test_y = train_test_split(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].dtype\n",
    "train_y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 23:46:33.390265: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-17 23:46:33.390304: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-17 23:46:33.390337: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dino): /proc/driver/nvidia/version does not exist\n",
      "2022-05-17 23:46:33.390812: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-17 23:46:41.319454: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 876787200 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# Converting to tensors\n",
    "train_x = tf.convert_to_tensor([tf.convert_to_tensor(i, np.uint8) for i in train_x])\n",
    "train_y = tf.convert_to_tensor([tf.convert_to_tensor(i, np.uint8) for i in train_y])\n",
    "test_x = tf.convert_to_tensor([tf.convert_to_tensor(i, np.uint8) for i in test_x])\n",
    "test_y = tf.convert_to_tensor([tf.convert_to_tensor(i, np.uint8) for i in test_y])\n",
    "\n",
    "train_x = tf.cast(train_x, tf.float64)\n",
    "test_x = tf.cast(test_x, tf.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(5, (2,2), activation='relu', input_shape = (30,30,1)))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(5, (2,2), activation = 'relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(81, activation='relu'))\n",
    "model.add(layers.Dense(51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 29, 29, 5)         25        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 5)         105       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 5)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 81)                14661     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 51)                4182      \n",
      "=================================================================\n",
      "Total params: 18,973\n",
      "Trainable params: 18,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3806/3806 [==============================] - 33s 8ms/step - loss: 0.8902 - sparse_categorical_accuracy: 0.7816 - val_loss: 0.0116 - val_sparse_categorical_accuracy: 0.9366\n",
      "Epoch 2/15\n",
      "3806/3806 [==============================] - 37s 10ms/step - loss: 0.0146 - sparse_categorical_accuracy: 0.9570 - val_loss: 0.0012 - val_sparse_categorical_accuracy: 0.9683\n",
      "Epoch 3/15\n",
      "3806/3806 [==============================] - 37s 10ms/step - loss: 0.0071 - sparse_categorical_accuracy: 0.9745 - val_loss: 0.0062 - val_sparse_categorical_accuracy: 0.9787\n",
      "Epoch 4/15\n",
      "3806/3806 [==============================] - 38s 10ms/step - loss: 0.0040 - sparse_categorical_accuracy: 0.9816 - val_loss: 0.0011 - val_sparse_categorical_accuracy: 0.9839\n",
      "Epoch 5/15\n",
      "3806/3806 [==============================] - 38s 10ms/step - loss: 0.0034 - sparse_categorical_accuracy: 0.9857 - val_loss: 8.7642e-04 - val_sparse_categorical_accuracy: 0.9871\n",
      "Epoch 6/15\n",
      "3806/3806 [==============================] - 38s 10ms/step - loss: 0.0039 - sparse_categorical_accuracy: 0.9882 - val_loss: 8.3206e-04 - val_sparse_categorical_accuracy: 0.9892\n",
      "Epoch 7/15\n",
      "3806/3806 [==============================] - 36s 9ms/step - loss: 0.0028 - sparse_categorical_accuracy: 0.9900 - val_loss: 0.0021 - val_sparse_categorical_accuracy: 0.9906\n",
      "Epoch 8/15\n",
      "3806/3806 [==============================] - 38s 10ms/step - loss: 0.0017 - sparse_categorical_accuracy: 0.9912 - val_loss: 0.0014 - val_sparse_categorical_accuracy: 0.9918\n",
      "Epoch 9/15\n",
      "3806/3806 [==============================] - 38s 10ms/step - loss: 0.0025 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0017 - val_sparse_categorical_accuracy: 0.9926\n",
      "Epoch 10/15\n",
      "3806/3806 [==============================] - 38s 10ms/step - loss: 0.0016 - sparse_categorical_accuracy: 0.9930 - val_loss: 3.8254e-04 - val_sparse_categorical_accuracy: 0.9934\n",
      "Epoch 11/15\n",
      "3806/3806 [==============================] - 36s 10ms/step - loss: 0.0018 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.0027 - val_sparse_categorical_accuracy: 0.9939\n",
      "Epoch 12/15\n",
      "3806/3806 [==============================] - 37s 10ms/step - loss: 2.7450e-05 - sparse_categorical_accuracy: 0.9942 - val_loss: 8.8692e-04 - val_sparse_categorical_accuracy: 0.9944\n",
      "Epoch 13/15\n",
      "3806/3806 [==============================] - 37s 10ms/step - loss: 1.6417e-07 - sparse_categorical_accuracy: 0.9947 - val_loss: 9.3787e-04 - val_sparse_categorical_accuracy: 0.9949\n",
      "Epoch 14/15\n",
      "3806/3806 [==============================] - 37s 10ms/step - loss: 3.4747e-08 - sparse_categorical_accuracy: 0.9950 - val_loss: 9.6541e-04 - val_sparse_categorical_accuracy: 0.9952\n",
      "Epoch 15/15\n",
      "3806/3806 [==============================] - 37s 10ms/step - loss: 9.0344e-09 - sparse_categorical_accuracy: 0.9954 - val_loss: 0.0011 - val_sparse_categorical_accuracy: 0.9956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff604a3a2c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "            )\n",
    "model.fit(train_x, train_y, epochs = 15, validation_data = (test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"myModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
